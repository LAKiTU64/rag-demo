import re
import os
import asyncio
import json
from pathlib import Path
import sys
from typing import Dict, List, Optional, Tuple

import yaml

# è®¾ç½®å¤šå¡ç¯å¢ƒ
os.environ["CUDA_VISIBLE_DEVICES"] = "0,1,2,3"

# å¯¼å…¥åˆ†æå·¥å…·
sys.path.insert(0, str(Path(__file__).parent))

from utils.nsys_to_ncu_analyzer import create_sglang_analysis_workflow
from offline_llm import get_offline_qwen_client
from knowledge_bases.vector_kb_manager import VectorKBManager


class AIAgent:
    """AI Agentæ ¸å¿ƒç±» - è‡ªåŠ¨åŒ–æ€§èƒ½åˆ†æï¼ˆæ”¯æŒ Agentic-RAGï¼‰"""

    def __init__(self, config: Dict):
        # === ä¿æŒåŸæ ·ï¼Œä¸åšä»»ä½•ä¿®æ”¹ ===
        self.config = config

        # sglang å’Œæ¨¡å‹è·¯å¾„
        self.sglang_path = Path(config.get("sglang_path"))
        self.models_path = Path(config.get("models_path"))
        self.model_mappings = config.get("model_mappings")

        # è¾“å‡ºç›®å½•
        self.results_dir = Path(config.get("output", {}).get("results_dir"))
        self.results_dir.mkdir(exist_ok=True)

        # æœ¬åœ° LLM å®¢æˆ·ç«¯ï¼ˆç”¨äº Agentic å†³ç­–ï¼‰
        self.offline_qwen_path = Path(config.get("offline_qwen_path"))
        self.llm_client = get_offline_qwen_client(self.offline_qwen_path)

        # åˆ†æå·¥å…·é…ç½®
        self.profiling_config = config.get("profiling_tools")
        self.analysis_defaults = config.get("analysis_defaults")

        # ç¼“å­˜
        self.last_analysis_dir: Optional[str] = None
        self.last_analysis_dirs: List[str] = []
        self.last_analysis_reports: List[str] = []
        self.last_analysis_table: Optional[str] = None

        # å‘é‡çŸ¥è¯†åº“ç›¸å…³
        self.kb = VectorKBManager()
        kb_config = config.get("vector_store")
        self.persist_directory = kb_config.get("persist_directory")
        self.embedding_model = kb_config.get("embedding_model")
        self.chunk_size = kb_config.get("chunk_size")
        self.chunk_overlap = kb_config.get("chunk_overlap")
        self.default_search_k = kb_config.get("default_search_k")
        self.similarity_threshold = kb_config.get("similarity_threshold")

    async def process_message(self, message: str) -> str:
        """
        Agentic-RAG ä¸»æµç¨‹ï¼š
        1. æ£€ç´¢çŸ¥è¯†åº“ï¼ˆæä¾›ä¸Šä¸‹æ–‡ï¼‰
        2. ç”± LLM å®Œå…¨è§£æç”¨æˆ·æ„å›¾ã€æ¨¡å‹ã€å‚æ•°ã€åˆ†æç±»å‹
        3. è‹¥è§£ææˆåŠŸ â†’ æ‰§è¡Œåˆ†æï¼›å¦åˆ™ â†’ æŠ›å‡ºå¼‚å¸¸
        """

        # Step 1: æ£€ç´¢çŸ¥è¯†åº“ï¼ˆç”¨äºä¸Šä¸‹æ–‡ï¼Œä¸å½±å“å†³ç­–ï¼‰
        retrieved_contexts = self.kb.search(query=message, k=3)
        rag_context = ""
        if retrieved_contexts:
            # ä½¿ç”¨å®Œæ•´å†…å®¹ï¼Œä¸æˆªæ–­
            rag_snippets = [
                f"ã€{res['doc_id']}ã€‘{res['content']}" for res in retrieved_contexts
            ]
            rag_context = "\n\n".join(rag_snippets)

        # Step 2: è®© LLM å®Œå…¨è§£æç»“æ„åŒ–è¯·æ±‚
        try:
            parsed_request = await self._parse_user_intent_with_llm(
                message, rag_context
            )
        except Exception as e:
            raise ValueError(f"LLM æ— æ³•è§£æç”¨æˆ·è¯·æ±‚: {e}")

        # Step 3: æ‰§è¡Œåˆ†æï¼ˆå”¯ä¸€å‡ºå£ï¼‰
        return await self._execute_analysis_flow(
            model_name=parsed_request["model"],
            analysis_type=parsed_request["analysis_type"],
            params=parsed_request["params"],
        )

    async def _parse_user_intent_with_llm(
        self, user_query: str, rag_context: str
    ) -> Dict:
        """
        ç”± LLM å®Œå…¨è§£æç”¨æˆ·æ„å›¾ï¼Œè¿”å›ä¸¥æ ¼ç»“æ„åŒ–å­—å…¸ã€‚
        """

        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªé«˜æ€§èƒ½è®¡ç®—ï¼ˆHPCï¼‰ä¸å¤§æ¨¡å‹æ€§èƒ½åˆ†æä¸“å®¶ã€‚è¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹è§„åˆ™è§£æç”¨æˆ·è¯·æ±‚ã€‚

### ç”¨æˆ·åŸå§‹è¯·æ±‚
{user_query}

### ç›¸å…³çŸ¥è¯†åº“ä¸Šä¸‹æ–‡ï¼ˆå¯é€‰å‚è€ƒï¼Œä½†ä¸è¦è¢«è¯¯å¯¼ï¼‰
{rag_context if rag_context else "æ— "}

### è¾“å‡ºè¦æ±‚
è¯·è¾“å‡ºä¸€ä¸ª **ä¸¥æ ¼ç¬¦åˆ JSON æ ¼å¼** çš„å¯¹è±¡ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
- "model": å­—ç¬¦ä¸²ï¼Œæ¨¡å‹åç§°ï¼ˆå¦‚ "qwen3-4b"ï¼‰ã€‚å¿…é¡»ä»ç”¨æˆ·è¯·æ±‚ä¸­æå–ï¼Œä¸è¦çŒœæµ‹ã€‚
- "analysis_type": å­—ç¬¦ä¸²ï¼Œå¿…é¡»æ˜¯ä»¥ä¸‹ä¹‹ä¸€ï¼š
    - "nsys" è¡¨ç¤ºå…¨å±€æ€§èƒ½åˆ†æï¼ˆnsight systemsï¼‰
    - "ncu" è¡¨ç¤ºæ·±åº¦ kernel åˆ†æï¼ˆnsight computeï¼‰
    - "auto" è¡¨ç¤ºé›†æˆåˆ†æï¼ˆnsys + ncuï¼‰
- "params": å¯¹è±¡ï¼ŒåŒ…å«ä»¥ä¸‹å¯é€‰æ•°å€¼æ•°ç»„ï¼š
    - "batch_size": æ•´æ•°åˆ—è¡¨ï¼Œå¦‚ [1]
    - "input_len": æ•´æ•°åˆ—è¡¨ï¼Œå¦‚ [128]
    - "output_len": æ•´æ•°åˆ—è¡¨ï¼Œå¦‚ [1]

### æ³¨æ„
- å¦‚æœç”¨æˆ·æœªæŒ‡å®š batch_size/input_len/output_lenï¼Œè¯·ä½¿ç”¨åˆç†é»˜è®¤å€¼ï¼ˆå¦‚ batch_size=[1]ï¼‰ã€‚
- ä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šã€Markdownã€æˆ–é¢å¤–æ–‡æœ¬ã€‚
- åªè¾“å‡º JSONã€‚

### ç¤ºä¾‹è¾“å‡º
{{"model": "qwen3-4b", "analysis_type": "auto", "params": {{"batch_size": [1], "input_len": [128], "output_len": [1]}}}}
"""

        raw_output = self.llm_client.generate(
            prompt,
            max_tokens=512,
            mode="structured",  # ğŸ‘ˆ å…³é”®ï¼šæŒ‡å®šä¸ºç»“æ„åŒ–ä»»åŠ¡
        ).strip()

        # å¼ºåˆ¶ JSON è§£æ
        if not (raw_output.startswith("{") and raw_output.endswith("}")):
            raise ValueError(f"LLM è¾“å‡ºé JSON æ ¼å¼: {raw_output[:200]}...")

        try:
            result = json.loads(raw_output)
        except json.JSONDecodeError as e:
            raise ValueError(f"JSON è§£æå¤±è´¥: {e} | åŸå§‹è¾“å‡º: {raw_output[:200]}...")

        # éªŒè¯å¿…è¦å­—æ®µ
        required_keys = {"model", "analysis_type", "params"}
        if not required_keys.issubset(result.keys()):
            raise ValueError(
                f"ç¼ºå°‘å¿…è¦å­—æ®µã€‚éœ€è¦: {required_keys}, å®é™…: {set(result.keys())}"
            )

        # ç¡®ä¿ params æ˜¯ dict
        if not isinstance(result["params"], dict):
            result["params"] = {}

        # è¡¥å…¨é»˜è®¤å‚æ•°ï¼ˆä»…å½“ç¼ºå¤±æ—¶ï¼‰
        defaults = self.analysis_defaults
        if "batch_size" not in result["params"]:
            result["params"]["batch_size"] = defaults.get("batch_size", [1])
        if "input_len" not in result["params"]:
            result["params"]["input_len"] = defaults.get("input_len", [128])
        if "output_len" not in result["params"]:
            result["params"]["output_len"] = defaults.get("output_len", [1])

        # æ ‡å‡†åŒ–åˆ†æç±»å‹
        at = result["analysis_type"].lower()
        if "ncu" in at or "kernel" in at or "compute" in at:
            result["analysis_type"] = "ncu"
        elif "nsys" in at or "systems" in at or "global" in at:
            result["analysis_type"] = "nsys"
        else:
            result["analysis_type"] = "auto"

        return result

    async def _execute_analysis_flow(
        self, model_name: str, analysis_type: str, params: Dict
    ) -> str:
        model_path = self._resolve_model_path(model_name)
        if not model_path:
            raise ValueError(
                f"æ¨¡å‹è·¯å¾„è§£æå¤±è´¥: '{model_name}'ã€‚å¯ç”¨æ¨¡å‹: {list(self.model_mappings.keys())}"
            )
        return await self._run_analysis(
            model_path=model_path, analysis_type=analysis_type, params=params
        )

    # ========== ä»¥ä¸‹æ–¹æ³•ä¿æŒä¸å˜ï¼ˆä» _run_analysis å¼€å§‹åˆ°æ–‡ä»¶ç»“æŸï¼‰==========
    # ï¼ˆä¸ºèŠ‚çœç¯‡å¹…ï¼Œæ­¤å¤„çœç•¥ï¼Œå®é™…ä½¿ç”¨æ—¶ä¿ç•™åŸä»£ç ï¼‰

    async def _run_analysis(
        self, model_path: str, analysis_type: str, params: Dict
    ) -> str:
        results = []
        self.last_analysis_table = None
        self.last_analysis_reports = []
        self.last_analysis_dirs = []
        self.last_analysis_dir = None

        batch_sizes = params.get("batch_size", [1])
        input_lens = params.get("input_len", [128])
        output_lens = params.get("output_len", [1])

        batch_size = batch_sizes[0] if isinstance(batch_sizes, list) else batch_sizes
        input_len = input_lens[0] if isinstance(input_lens, list) else input_lens
        output_len = output_lens[0] if isinstance(output_lens, list) else output_lens

        # ========== æ–°å¢ï¼šæµ‹è¯•æ¨¡å¼ - è·³è¿‡çœŸå®åˆ†æ ==========
        if os.getenv("AGENT_TEST_MODE", "0") == "1":
            mock_report = """
ä¸€ã€æ€»ä½“ç»Ÿè®¡
- æ€»kernelsæ•°é‡: 42
- æ€»kernelæ‰§è¡Œæ—¶é—´: 125.6 ms

äºŒã€çƒ­ç‚¹Kernelsï¼ˆæŒ‰æ—¶é—´é™åºï¼‰
1. flash_attn_fwd_kernel
   - æ‰§è¡Œæ—¶é—´: 45.2 ms
   - æ—¶é—´å æ¯”: 36.0%
2. rms_norm_kernel
   - æ‰§è¡Œæ—¶é—´: 28.7 ms
   - æ—¶é—´å æ¯”: 22.8%
3. fused_mlp_kernel
   - æ‰§è¡Œæ—¶é—´: 18.3 ms
   - æ—¶é—´å æ¯”: 14.6%
"""
            report_path = self.results_dir / "mock_integrated_performance_report.md"
            report_path.write_text(mock_report.strip(), encoding="utf-8")
            run_records = [("0", self.results_dir)]
        else:
            try:
                analysis_workflow = create_sglang_analysis_workflow()
                workflow_output = await asyncio.get_event_loop().run_in_executor(
                    None,
                    analysis_workflow,
                    str(model_path),
                    batch_size,
                    input_len,
                    output_len,
                )

                run_records: List[Tuple[str, Path]] = []
                if isinstance(workflow_output, list):
                    for idx, item in enumerate(workflow_output):
                        gpu_label: str
                        output_path: Optional[str] = None
                        if isinstance(item, dict):
                            gpu_label = str(item.get("gpu", idx))
                            output_path = item.get("dir") or item.get("path")
                        else:
                            gpu_label = str(idx)
                            output_path = str(item)
                        if output_path:
                            run_records.append((gpu_label, Path(output_path)))
                elif workflow_output:
                    run_records.append(("0", Path(str(workflow_output))))

                if not run_records:
                    raise RuntimeError("åˆ†æå®Œæˆä½†æœªè¿”å›è¾“å‡ºç›®å½•")

            except Exception as e:
                import traceback

                error_detail = traceback.format_exc()
                return f"""
âŒ **åˆ†ææ‰§è¡Œå¤±è´¥**

é”™è¯¯ä¿¡æ¯: {str(e)}

è¯¦ç»†é”™è¯¯:
{error_detail}

ğŸ’¡ **å¸¸è§é—®é¢˜è§£å†³**:
1. ç¡®ä¿å·²å®‰è£… nsys å’Œ ncu å·¥å…·
2. ç¡®ä¿ SGlang å·²æ­£ç¡®å®‰è£…
3. ç¡®ä¿æ¨¡å‹æ–‡ä»¶è·¯å¾„æ­£ç¡®
4. ç¡®ä¿æœ‰è¶³å¤Ÿçš„ GPU å†…å­˜
"""

        # ========== å…¬å…±åå¤„ç†é€»è¾‘ ==========
        self.last_analysis_dirs = [str(path) for _, path in run_records]

        report_infos = []
        missing_reports = []
        for idx, (gpu_label, output_dir) in enumerate(run_records):
            report_path = output_dir / "integrated_performance_report.md"
            if report_path.exists():
                report_text = report_path.read_text(encoding="utf-8")
                report_infos.append(
                    {
                        "gpu": gpu_label,
                        "dir": output_dir,
                        "report": report_path,
                        "text": report_text,
                        "index": idx,
                    }
                )
            else:
                missing_reports.append(output_dir)

        if not report_infos:
            dir_lines = "\n".join(f"  â€¢ {path}" for _, path in run_records)
            return f"""
âš ï¸ **åˆ†æå·²å®Œæˆï¼Œä½†æœªç”ŸæˆæŠ¥å‘Šæ–‡ä»¶**

ğŸ“ ç»“æœç›®å½•:
{dir_lines}
ğŸ’¡ è¯·æ£€æŸ¥ç›®å½•ä¸­çš„å…¶ä»–è¾“å‡ºæ–‡ä»¶
"""

        primary_info = report_infos[0]
        self.last_analysis_dir = str(primary_info["dir"])
        self.last_analysis_reports = [str(info["report"]) for info in report_infos]
        summary = self._extract_report_summary(primary_info["text"])

        try:
            loop = asyncio.get_event_loop()
            if len(report_infos) > 1:
                table_markdown = self._generate_multi_gpu_table(
                    [info["text"] for info in report_infos],
                    [info["gpu"] for info in report_infos],
                )
            else:
                table_markdown = await loop.run_in_executor(
                    None, self._generate_report_table, primary_info["text"]
                )
        except Exception as table_exc:
            table_markdown = f"âš ï¸ è¡¨æ ¼ç”Ÿæˆå¤±è´¥: {table_exc}"

        self.last_analysis_table = table_markdown

        dir_lines = "\n".join(
            f"  â€¢ {self._format_gpu_label(info['gpu'], info['index'])}: {info['dir']}"
            for info in report_infos
        )

        missing_lines = ""
        if missing_reports:
            missing_lines = "\n".join(f"  â€¢ {path}" for path in missing_reports)
            missing_lines = f"\nâš ï¸ æœªæ‰¾åˆ°ä»¥ä¸‹ç›®å½•çš„æŠ¥å‘Šæ–‡ä»¶:\n{missing_lines}\n"

        return f"""
âœ… **åˆ†æå®Œæˆ!**

ğŸ“ **ç»“æœç›®å½•**:
{dir_lines}
ğŸ“„ **æŠ¥å‘Šæ–‡ä»¶**: {primary_info["report"]}
{missing_lines}
{summary}

ğŸ“Œ **çƒ­ç‚¹Kernelè¡¨æ ¼é¢„è§ˆ**:
{table_markdown}

ğŸ” **è¯¦ç»†æŠ¥å‘Š**: è¯·æŸ¥çœ‹ {primary_info["report"]}
ğŸ“Š **å¯è§†åŒ–å›¾è¡¨**: è¯·æŸ¥çœ‹å¯¹åº”ç»“æœç›®å½•ä¸­çš„å›¾ç‰‡æ–‡ä»¶
"""

    @staticmethod
    def _generate_report_table(report_text: str) -> str:
        # æ³¨æ„ï¼šè¿™é‡Œä¿®æ­£äº†åŸä»£ç çš„ bugï¼ˆå¤šäº†ä¸€ä¸ª self å‚æ•°ï¼‰
        from offline_llm import get_offline_qwen_client

        # å®é™…åº”ä»é…ç½®è·å–è·¯å¾„ï¼Œä½†ä¸ºç®€åŒ–ï¼Œå‡è®¾ client å·²å­˜åœ¨
        # æ›´å¥½çš„åšæ³•æ˜¯ä¼ å…¥ clientï¼Œä½†ä¸ºå…¼å®¹æ€§ï¼Œä¸´æ—¶é‡å»º
        # TODO: åç»­å¯æ³¨å…¥ client
        client = get_offline_qwen_client(Path(__file__).parent / "dummy")  # ä»…ç¤ºæ„
        return client.report_to_table(report_text)

    def _generate_multi_gpu_table(
        self, report_texts: List[str], gpu_labels: List[str]
    ) -> str:
        if not report_texts:
            return "âš ï¸ æœªæ‰¾åˆ°å¯ç”¨çš„æŠ¥å‘Šå†…å®¹"

        parsed_entries = [
            self._parse_kernel_entries_from_report(text) for text in report_texts
        ]
        if not parsed_entries or not parsed_entries[0]:
            return "âš ï¸ æœªèƒ½è§£æå¤šGPUè¡¨æ ¼æ•°æ®"

        label_cells = [
            self._format_gpu_label(lbl, idx) for idx, lbl in enumerate(gpu_labels)
        ]
        header_cells = ["Kernel"]
        for lbl in label_cells:
            header_cells.extend([f"{lbl} Duration(ms)", f"{lbl} Ratio(%)"])

        header = "| " + " | ".join(header_cells) + " |"
        divider = "| " + " | ".join(["---"] * len(header_cells)) + " |"

        max_len = max(len(entries) for entries in parsed_entries)
        rows = []
        for idx in range(max_len):
            name_candidates = []
            for entries in parsed_entries:
                if idx < len(entries) and entries[idx]["name"]:
                    name_candidates.append(entries[idx]["name"])
            base_name = name_candidates[0] if name_candidates else f"Kernel {idx + 1}"
            alt_names = {nm for nm in name_candidates if nm != base_name}
            if alt_names:
                merged_name = base_name + " / " + " / ".join(sorted(alt_names))
            else:
                merged_name = base_name

            row_cells = [merged_name]
            for entries in parsed_entries:
                if idx < len(entries):
                    row_cells.append(entries[idx]["duration"])
                    row_cells.append(entries[idx]["ratio"])
                else:
                    row_cells.extend(["", ""])
            rows.append("| " + " | ".join(row_cells) + " |")

        return "\n".join([header, divider, *rows])

    def _parse_kernel_entries_from_report(
        self, report_text: str
    ) -> List[Dict[str, str]]:
        entries: List[Dict[str, str]] = []
        lines = report_text.splitlines()
        idx = 0
        total_lines = len(lines)
        while idx < total_lines:
            raw_line = lines[idx]
            if raw_line.strip().startswith("äºŒã€"):
                break
            match = re.match(r"^\s*\d+\.\s+(.*)$", raw_line)
            if match:
                name = match.group(1).strip()
                duration = ""
                ratio = ""
                idx += 1
                while idx < total_lines:
                    line = lines[idx].strip()
                    if line.startswith("- æ‰§è¡Œæ—¶é—´"):
                        dur_match = re.search(r"([0-9.]+)\s*ms", line)
                        if dur_match:
                            duration = dur_match.group(1)
                    elif line.startswith("- æ—¶é—´å æ¯”"):
                        ratio_match = re.search(r"([0-9.]+)\s*%", line)
                        if ratio_match:
                            ratio = ratio_match.group(1)
                    elif re.match(r"^\s*\d+\.", lines[idx]) or line.startswith("äºŒã€"):
                        break
                    idx += 1
                entries.append({"name": name, "duration": duration, "ratio": ratio})
            else:
                idx += 1
        return entries

    @staticmethod
    def _format_gpu_label(label: str, index: int) -> str:
        if not label:
            return f"GPU{index}"
        normalized = label.strip()
        if not normalized:
            return f"GPU{index}"
        if normalized.lower().startswith("gpu"):
            return normalized.upper()
        return f"GPU{normalized}"

    def _extract_report_summary(self, report_content: str) -> str:
        lines = report_content.split("\n")
        summary_lines = []

        for i, line in enumerate(lines):
            if "æ€»kernelsæ•°é‡" in line or "æ€»kernelæ‰§è¡Œæ—¶é—´" in line:
                summary_lines.append(line)
            elif "ğŸ”¥ è¯†åˆ«çš„çƒ­ç‚¹Kernels" in line:
                summary_lines.append("\n**ğŸ”¥ çƒ­ç‚¹Kernels (Top 3):**")
                for j in range(i + 1, min(i + 10, len(lines))):
                    if lines[j].strip() and lines[j].startswith(("1.", "2.", "3.")):
                        summary_lines.append(lines[j][:100])
                break

        if summary_lines:
            return "\n".join(summary_lines)
        else:
            return "**ğŸ“Š åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆï¼Œè¯·æŸ¥çœ‹è¯¦ç»†æ–‡ä»¶**"

    def _resolve_model_path(self, model_name: str) -> Optional[str]:
        if model_name in self.model_mappings:
            mapped_path = self.model_mappings[model_name]
            if Path(mapped_path).is_absolute():
                return mapped_path
            full_path = self.models_path / mapped_path
            return str(full_path)

        if Path(model_name).exists():
            return model_name

        potential_path = self.models_path / model_name
        if potential_path.exists():
            return str(potential_path)

        return None

    def _extract_model_name(self, prompt: str) -> Optional[str]:
        # æ­¤æ–¹æ³•ç°åœ¨ä»…ç”¨äº _resolve_model_path çš„è¾…åŠ©ï¼Œä¸»é€»è¾‘ç”± LLM è´Ÿè´£
        for model_name in self.model_mappings.keys():
            if model_name.lower() in prompt.lower():
                return model_name

        patterns = [
            r"llama[^/\s]*-?\d*[^/\s]*-?\d+[bB]?",
            r"qwen[^/\s]*-?\d*[^/\s]*-?\d+[bB]?",
            r"chatglm[^/\s]*-?\d+[bB]?",
            r"baichuan[^/\s]*-?\d+[bB]?",
            r"vicuna[^/\s]*-?\d+[bB]?",
            r"mistral[^/\s]*-?\d+[bB]?",
            r"mixtral[^/\s]*-?\d+[bB]?",
        ]

        for pattern in patterns:
            match = re.search(pattern, prompt, re.IGNORECASE)
            if match:
                return match.group(0)

        return None

    def _extract_analysis_type(self, prompt: str) -> str:
        # æ­¤æ–¹æ³•ç°åœ¨ä»…ç”¨äº fallbackï¼ˆä½†å·²ç§»é™¤ï¼‰ï¼Œä¿ç•™ä»…ä¸ºå…¼å®¹
        prompt_lower = prompt.lower()
        if (
            "ncu" in prompt_lower
            or "kernel" in prompt_lower
            or "æ·±åº¦" in prompt_lower
            or "nsight compute" in prompt_lower
        ):
            return "ncu"
        elif (
            "nsys" in prompt_lower
            or "å…¨å±€" in prompt_lower
            or "nsight systems" in prompt_lower
        ):
            return "nsys"
        else:
            return "auto"

    def _extract_parameters(self, prompt: str) -> Dict:
        # æ­¤æ–¹æ³•ç°åœ¨ä»…ç”¨äº fallbackï¼ˆä½†å·²ç§»é™¤ï¼‰ï¼Œä¿ç•™ä»…ä¸ºå…¼å®¹
        params = {}
        batch_match = re.search(
            r"batch[-_\s]*size?[ï¼š:\s=]*(\d+(?:\s*[,ï¼Œ]\s*\d+)*)", prompt, re.IGNORECASE
        )
        if batch_match:
            batch_sizes = [
                int(x.strip())
                for x in re.split(r"[,ï¼Œ\s]+", batch_match.group(1))
                if x.strip()
            ]
            params["batch_size"] = batch_sizes

        input_match = re.search(
            r"input[-_\s]*len[gth]*[ï¼š:\s=]*(\d+(?:\s*[,ï¼Œ]\s*\d+)*)",
            prompt,
            re.IGNORECASE,
        )
        if input_match:
            input_lens = [
                int(x.strip())
                for x in re.split(r"[,ï¼Œ\s]+", input_match.group(1))
                if x.strip()
            ]
            params["input_len"] = input_lens

        output_match = re.search(
            r"output[-_\s]*len[gth]*[ï¼š:\s=]*(\d+(?:\s*[,ï¼Œ]\s*\d+)*)",
            prompt,
            re.IGNORECASE,
        )
        if output_match:
            output_lens = [
                int(x.strip())
                for x in re.split(r"[,ï¼Œ\s]+", output_match.group(1))
                if x.strip()
            ]
            params["output_len"] = output_lens

        return params

    def get_available_models(self) -> List[str]:
        return list(self.model_mappings.keys())

    def get_analysis_status(self) -> Dict:
        return {
            "available_models": self.get_available_models(),
            "results_directory": str(self.results_dir),
            "nsys_enabled": self.profiling_config.get("nsys", {}).get("enabled", True),
            "ncu_enabled": self.profiling_config.get("ncu", {}).get("enabled", True),
        }


# ==================== ç®€å•æµ‹è¯•ç”¨ä¾‹ ====================
if __name__ == "__main__":
    import yaml
    from pathlib import Path
    import asyncio

    # å¯¼å…¥config
    with open("config.yaml", "r", encoding="utf-8") as f:
        config_yaml = yaml.safe_load(f)

    # agentåˆå§‹åŒ–
    agent = AIAgent(config_yaml)

    # æ„å»ºçŸ¥è¯†åº“
    document_dir = Path("documents")
    if document_dir.exists():
        for file_path in document_dir.iterdir():
            if file_path.is_file():
                agent.kb.add_document(str(file_path))
                print(f"å·²æ·»åŠ æ–‡æ¡£: {file_path}")
    else:
        print(f"æ–‡æ¡£ç›®å½•ä¸å­˜åœ¨: {document_dir}")

    # ==============================
    # ğŸ”§ æ–°å¢ï¼šæµ‹è¯•ç»“æ„åŒ–æ„å›¾è§£æï¼ˆè°ƒè¯•ç”¨ï¼‰
    # ==============================
    async def test_structured_parsing():
        print("\nğŸ§ª æµ‹è¯•ç»“æ„åŒ–æ„å›¾è§£æ...")
        user_query = "åˆ†æä¸€ä¸‹qwen3-4bæ¨¡å‹ï¼Œbatch_size=1"
        rag_context = ""  # å¯ç•™ç©ºæˆ–æ¨¡æ‹Ÿ
        try:
            intent = await agent._parse_user_intent_with_llm(user_query, rag_context)
            print(f"âœ… è§£ææˆåŠŸ: {intent}")
        except Exception as e:
            print(f"âŒ è§£æå¤±è´¥: {e}")

    # ==============================
    # ğŸ” åŸæœ‰ï¼šç«¯åˆ°ç«¯é—®ç­”æµ‹è¯•
    # ==============================
    async def run_end_to_end_test():
        print("\nğŸ” ç«¯åˆ°ç«¯é—®ç­”æµ‹è¯•...")
        try:
            response = await agent.process_message("åˆ†æä¸€ä¸‹qwen3-4bæ¨¡å‹ï¼Œbatch_size=1")
            print(f"âœ… æœ€ç»ˆå“åº”:\n{response}")
        except Exception as e:
            print(f"âŒ å¼‚å¸¸: {e}")

    # ==============================
    # ğŸš€ è¿è¡Œæµ‹è¯•
    # ==============================
    print("ğŸš€ å¯åŠ¨æµ‹è¯•å¥—ä»¶")
    asyncio.run(test_structured_parsing())  # å…ˆæµ‹è§£æ
    asyncio.run(run_end_to_end_test())  # å†æµ‹å®Œæ•´æµç¨‹
