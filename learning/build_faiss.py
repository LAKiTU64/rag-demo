import os

from langchain_community.document_loaders import TextLoader
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter  # å»ºè®®ä»ä¸“ç”¨åŒ…å¯¼å…¥

# 0. é…ç½®å›½å†…é•œåƒæº
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"


def build_vector_store(file_path: str, index_save_path: str):
    # 1. åŠ è½½æ–‡æ¡£
    if not os.path.exists(file_path):
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {file_path}")
        return

    loader = TextLoader(file_path, encoding="utf-8")
    docs = loader.load()

    # 2. åˆ†å‰²æ–‡æœ¬
    # æ³¨æ„ï¼šæœ€æ–°çš„åº“å»ºè®®ä» langchain_text_splitters å¯¼å…¥
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=300,  # ä¸­æ–‡å»ºè®®ç¨å¾®å¤§ä¸€ç‚¹ç‚¹ï¼Œä¿è¯è¯­å¢ƒå®Œæ•´
        chunk_overlap=30,
        add_start_index=True,  # ä¿ç•™åŸå§‹ä½ç½®ä¿¡æ¯ï¼Œæ–¹ä¾¿æº¯æº
    )
    splits = text_splitter.split_documents(docs)
    print(f"ğŸ“¦ å·²å°†æ–‡æ¡£åˆ†å‰²ä¸º {len(splits)} ä¸ªä»£ç å—")

    # 3. åˆå§‹åŒ– Embedding æ¨¡å‹
    # æ¨èä½¿ç”¨ BGE ç³»åˆ—ï¼Œå¯¹ä¸­æ–‡æ”¯æŒæå¥½ä¸”ä½“ç§¯é€‚ä¸­
    model_name = "BAAI/bge-small-zh-v1.5"
    encode_kwargs = {"normalize_embeddings": True}  # å½’ä¸€åŒ–ï¼Œæå‡æ£€ç´¢ç²¾åº¦

    embeddings = HuggingFaceEmbeddings(
        model_name=model_name,
        model_kwargs={"device": "cpu"},  # å¦‚æœæœ‰GPUå¯æ”¹ä¸º 'cuda'
        encode_kwargs=encode_kwargs,
    )

    # 4. æ„å»º FAISS å‘é‡åº“
    print("ğŸš€ æ­£åœ¨æ„å»ºå‘é‡ç´¢å¼•ï¼Œè¯·ç¨å€™...")
    vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)

    # 5. æŒä¹…åŒ–å­˜å‚¨
    vectorstore.save_local(index_save_path)
    print(f"âœ… FAISS å‘é‡åº“å·²æˆåŠŸä¿å­˜åˆ°: {index_save_path}")


if __name__ == "__main__":
    DATA_FILE = "./learning/test_data.txt"
    SAVE_PATH = "./learning/faiss_index"
    build_vector_store(DATA_FILE, SAVE_PATH)
